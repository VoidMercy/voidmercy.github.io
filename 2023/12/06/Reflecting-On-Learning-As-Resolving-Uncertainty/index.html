<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8" />

    

    

    <title>Reflecting On Learning As Resolving Uncertainty | Hexo</title>
    <meta name="author" content="John Doe" />
    <meta name="keywords" content="" />
    <meta name="description" content="I recently took the course EE 277 taught by Professor Benjamin Van Roy, which was an excellent course. This course made me think deeply about what it means for a system to learn about an environment, how probability and statistics play a role in mode" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=no" />

    
    <link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">
    
    
    <link rel="icon" href="/images/favicon.ico">
    

    <style type="text/css">
    @font-face {
        font-family: 'icomoon';
        src: url("/fonts/icomoon.eot?q628ml");
        src: url("/fonts/icomoon.eot?q628ml#iefix") format('embedded-opentype'),
             url("/fonts/icomoon.ttf?q628ml") format('truetype'),
             url("/fonts/icomoon.woff?q628ml") format('woff'),
             url("/fonts/icomoon.svg?q628ml#icomoon") format('svg');
        font-weight: normal;
        font-style: normal;
    }
    </style>
    
<link rel="stylesheet" href="/css/style.css">


    <!--[if lt IE 9]><style type="text/css">.nav-inner {top:0;}.author-meta {position:static;top:0;}.search-form {height:36px;}</style><script type="text/javascript" src="https://unpkg.com/html5shiv@3.7.3/dist/html5shiv.min.js"></script><![endif]-->
<meta name="generator" content="Hexo 7.0.0"></head>
<body>

    <main class="app">
        <header id="header" class="header clearfix">
    <div id="nav" class="nav">
    <div class="nav-mobile">
        <button id="open-panel" class="open-panel nav-mobile-item"><i class="icon-documents"></i></button>
        <h1 class="nav-mobile-title nav-mobile-item">Hexo</h1>
        <button id="open-menus" class="open-panel nav-mobile-item"><i class="icon-library"></i></button>
    </div>

    <nav id="nav-inner" class="nav-inner">
        
            <a class="nav-item" href="/">
                <span class="nav-text">Posts</span>
            </a>
        
            <a class="nav-item" href="/about">
                <span class="nav-text">About</span>
            </a>
        
            <a class="nav-item" href="/contact">
                <span class="nav-text">Contact</span>
            </a>
        
    </nav>
</div>

    <aside id="aside" class="aside">
    <div id="aside-mask" class="aside-mask"></div>
    <div id="aside-inner" class="aside-inner">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit"><i class="icon-search-stroke"></i></button><input type="hidden" name="sitesearch" value="https://voidmercy.github.io"></form>

        
        
        
        

        
        <div class="author-meta">
            
            <div class="author-avatar">
                <a href="/">
                    <img src="/images/avatar.jpg" title="Alex Lin">
                </a>
            </div>
            
            <div class="author-name">Alex Lin</div>
            <div class="author-work">Apple Engineer | Stanford Student</div>
            <div class="author-location">
                <i class="icon-location vm"></i>
                <span class="vm">Mountain View, California</span>
            </div>
            
            <div class="author-thread-wrap">
                <div class="author-threads clearfix">
                    
                        <a class="thread-item" href="https://github.com/voidmercy" target="_blank" rel="noopener">
                            <!-- Generated by IcoMoon.io -->
<svg viewBox="0 0 1024 1024" width="38" height="38" fill="currentColor">
<path d="M512 32.12c-265.004 0-479.88 220.23-479.88 492.090 0 217.446 137.536 401.684 328.202 466.81 23.994 4.498 32.778-10.712 32.778-23.78 0-11.782-0.428-42.632-0.642-83.764-133.466 29.778-161.744-65.984-161.744-65.984-21.852-56.772-53.344-71.982-53.344-71.982-43.49-30.636 3.214-29.992 3.214-29.992 48.202 3.428 73.482 50.772 73.482 50.772 42.846 75.196 112.258 53.558 139.68 40.918 4.284-31.706 16.71-53.558 30.42-65.77-106.474-12.426-218.516-54.63-218.516-243.152 0-53.772 18.638-97.69 49.274-131.966-4.928-12.426-21.424-62.556 4.714-130.252 0 0 40.276-13.282 131.966 50.344 38.348-10.926 79.266-16.282 120.184-16.496 40.704 0.214 81.836 5.57 120.184 16.496 91.692-63.626 131.752-50.344 131.752-50.344 26.136 67.698 9.64 117.828 4.714 130.252 30.636 34.492 49.274 78.408 49.274 131.966 0 188.952-112.258 230.514-219.16 242.724 17.138 15.21 32.564 45.202 32.564 91.048 0 65.77-0.642 118.898-0.642 134.966 0 13.068 8.57 28.492 32.992 23.566 191.094-64.912 328.418-249.152 328.418-466.382 0-271.86-214.874-492.090-479.88-492.090z"></path>
</svg>

                        </a>
                    
                </div>
            </div>
            
        </div>
        
    </div>
</aside>

</header>

        <div id="content" class="content">
            <div id="wrapper" class="wrapper" style="max-width: 800px">
                <article class="article" itemscope itemprop="blogPost">
    
    <header class="article-header">
        
        <h1 itemprop="name">
            Reflecting On Learning As Resolving Uncertainty
        </h1>
        
        <div class="article-meta clearfix">
            <a class="article-date" href="https://voidmercy.github.io/2023/12/06/Reflecting-On-Learning-As-Resolving-Uncertainty/index.html">
    
    <i class="icon-calendar vm"></i>
    
    <time class="vm" datetime="2023-12-06T08:52:32.000Z" itemprop="datePublished">2023-12-06</time>
</a>

            

        </div>
    </header>
    
    <section class="article-body markdown-body">
        
        <p>I recently took the course <a target="_blank" rel="noopener" href="https://explorecourses.stanford.edu/search?q=EE+277&view=catalog&page=0&filter-coursestatus-Active=on&collapse=&academicYear=20232024">EE 277</a> taught by Professor Benjamin Van Roy, which was an excellent course. This course made me think deeply about what it means for a system to learn about an environment, how probability and statistics play a role in modeling environment and uncertainly, and how Bayesian statistics (conditional probabilities really) can form the basis of approximate algorithms to model posterier distributions of random variables. This post will highlight the key ideas introduced and reinforced in this course, and how these ideas might play a role in the future of ML along with my subjective opinions.</p>
<p>The key ideas in this course:</p>
<ul>
<li>Model the environment using a probabilistic model. Unknowns are given a prior distribution.</li>
<li>Choose action which balances exploration of different actions and exploitation of optimal actions.</li>
<li>Based on actions and observations, compute the posterior distribution.</li>
<li>When choosing an action, we should consider both the expected reward and the information the action reveals about the uncertainty in the environment using shannon entropy.</li>
</ul>
<span id="more"></span>

<p>“All models are wrong. Some are just more useful than others.” I think this quote captures the essence of models taught in this course. Models are a method to predict things we are interested in. In reality, we don’t know how to perfectly model what we are trying to predict. Hence, we devise models and fit the environment we are trying to predict into the model’s formulation, and hope that it can be useful in predicting what we are interested in accurately. To devise better models require hypothesis, data, and experimentation - in other words, the scientific process. In practice, people take well-established models from the scientific communitiy and apply them to practical problems, often times trying many models and testing which one performs the best. This course models problems using linear models on feature vectors, whcih is a key idea in machine learning. From linear regression, to logistic regression, to GLMs, then SVMs, and finally neural networks - the main idea behind all of these techniques is to hand-craft or learn a good feature vector based on raw data, and then operate linearly on the features. However, what this course introduces is uncertainty in the model parameters - a Bayesian idea. Often times there is a distribution behind the true environment we’re interested in, not just a MAP estimate which most neural networks do. The process of learning is then captured as reducing uncertainty in the distribution of the uncertain elements in the environment.</p>
<p>The techniques presented in this class advocate for data efficiency. In most cases in this course, an optimal strategy tries to achieve the least cumulative regret as time goes to infinity. This requires balancing exploitation, exploration and information. Exploitation tries to maximize reward to reduce cumulative regret. Exploration tries to find the optimal action. Information builds on top of exploration to choose the action(s) that would help us find the optimal action more quickly by giving us more information. For simple models, these ideas can be applied perfectly since all quantites can be analytically computed and solved for. However, for most practical problems, the computation of exact quantities is impossible, which is why we rely on approximation techniques. Most elegant solutions to problems in all sorts of fields I have seen have a very elegant theoretical algorithm behind it, but what is actually implemented is an approximation of the theory. Sometimes, when looking at just the implementation of an approximation, it is very difficult to see the higher level of abstraction beyond the implementation, yet there exists a beautiful interpretation of the algorithm. Stumbling upon the higher level of abstraction usually requires a breakthrough, whcih seems to be up to chance based on the history of scientific discoveries. So to me, it’s not a question of whether there is a theory of everything, but it’s a question of when we will discover it.</p>
<p>Professor Van Roy mentioned that these ideas are critical to the current state of machine learning and LLMs. Specifically, currently foundational models are using RLHF techniques to fine-tune the model. If we think of the foundational model as a prior over grammar and knowledge that makes sense, amassed from internet data, then RLHF is steering the prior towards a specific task that we want. Empircally, the amount of RLHF data require to fine-tune is extremely little, perhaps 100,000 data points, where each data point is a single bit of information which decides which two responses is preferred. This might make sense, since in a optimal world, the two prompts recommended by the model will split the prior in half, and the user’s reponse will tell the model which side of the prior to choose. In practice, there is loss of efficiency, but 2^100000 is extremely large, so a big loss in efficiency is not too much of a concern. Perhaps if the model itself tries to explore and seek information by deliberately choosing its prompts, it could be fine-tuned much better and more efficiently. The architecture of transformer LLMs might be able to be formulated as a generalized linaer model on feature vectors, since a transformer learns an embedding vector which can be taken as a feature vector. Now based on this information, the question to ask ourselves is whether a foundational model can exhibit creativity after fine-tuning? I think there are arguments for both sides, so it remains yet to be seen. The argument for yes is that the prior distribution of the foundational model is extremely broad, so creative ideas may have an extremely small chance of being selected, but it’s still possible. Perhaps with the proper fine tuning, we can enhance the creative thoughts that we want. The argument for no is that fine-tuning for creativity would be too difficult in practice to analyze and evaluate, thus stunting progress - or that the prior is not broad enough.</p>
<p>Another curious thing that was mentioned during the course is whether introducing probability theory to students would bias the way students thought about uncertainty. This thought can be applied to not just probability theory, but education in general. How often is the potential of a new student stunted by the biases of content taught in schools? What does it take to not be biased by things you learn in school? Geniuses are often thought of to think differently - what causes this differnece in thinking? If two students experience the same education, do they come up with different ideas from each other? Probably yes, so is it attributed to different brain structure or brain learning algorithms? It’s really difficult to think about these questions. It seems that coming up with coherent theories is a very difficult task. In an ideal world, students would be shown data from experiments and be tasked with coming up with theories which support this data - which is part of the scientific process. In this way, we are limiting the bias imposed on thinking, perhaps then stimulating more creative thought and possibilites of breakthroughs. However, in practice I think many people would struggle with this. A curious question is whether a person can revert their own thought process after already being biased? The answer is probably yes, since if a person’s will to alter their own brain structure and thinking is strong enough, they can do it, as evidenced by mental diseases. I wonder what I could come up with had I not been exposed to these biases? How would I think about uncertainty? Or how would I model mathematics? Perhaps strong intuition is the key to understanding something fundamentally and coming up with mental models or theories.</p>
<p>My opinion is that machine learning models are not there yet - the theory behind architectures is not elegant yet and I don’t think the behavior and understanding of how these models learn is fully understood yet. I strongly believe there is always an elegant theory. However, coming up with theories is difficult - only time will tell what theories humans come up with next.</p>

        
    </section>
</article>




            </div>
        </div>

        
            
            <a id="pagenext" href="/2020/07/31/Using-Ghidra-for-Automated-Struct-Identification/" class="article-next" title="Using Ghidra for Automated Struct Identification"><i class="icon-arrow-right"></i></a>
            
            
            <a id="pageprev" href="/2024/04/30/All-the-courses-I-took-at-Stanford/" class="article-prev" title="All the courses I took at Stanford"><i class="icon-arrow-left"></i></a>
            
        

        <footer class="footer">
    Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>, Theme by <a href="https://github.com/sanonz/hexo-theme-concise" target="_blank">Concise</a>

    
</footer>

    </main>

    <script type="text/javascript" src="https://unpkg.com/jquery@1.9.1/jquery.min.js"></script>
    <script type="text/javascript">
    $(function() {
        var nodes = {
            nav: $('#nav'),
            aside: $('#aside'),
            asideInner: $('#aside-inner'),
            navInner: $('#nav-inner')
        };

        var doing = false;
        nodes.asideInner.on('webkitAnimationEnd mozAnimationEnd oAnimationEnd oanimationend animationend', function() {
            if (nodes.aside.hasClass('mobile-open')) {
                nodes.aside.removeClass('mobile-open');
            } else {
                nodes.aside.removeClass('mobile-close panel-show');
            }
            doing = false;
        });
        $('#open-panel, #aside-mask').on('click', function() {
            if (doing) {
                return;
            }

            if (nodes.aside.hasClass('panel-show')) {
                nodes.aside.addClass('mobile-close');
            } else {
                nodes.aside.addClass('mobile-open panel-show');
            }
        });
        $('#open-menus').on('click', function() {
            nodes.navInner.slideToggle('normal', slideDone);
        });

        if (window.innerWidth <= 960) {
            setTimeout(function() {
                nodes.navInner.slideUp('normal', slideDone);
            }, 3000);
        }

        function slideDone() {
            if (nodes.navInner.css('display') !== 'none') {
                nodes.navInner.css('display', '');
            }
        }

        $(window).on('resize', function() {
            if ($(this).width() > 960) {
                nodes.navInner.css('display', '');
            }
        });
    });
    </script>
    
        
<script src="/js/scrollspy.min.js"></script>

        <script type="text/javascript">
        $(document.body).scrollspy({target: '#aside-inner'});

        $(window).on('resize', function() {
            var hw = $('#header').width();
            var ww = $('#wrapper').width();
            var space = ($(this).width() - hw - ww) / 2 / 2;

            var pageprev = $('#pageprev');
            var pagenext = $('#pagenext');
            var avg = (pageprev.width() + pagenext.width()) / 2

            if(space > avg) {
                var len = space - avg / 2;
                var styles = {position: 'fixed', top: '50%', marginTop: - (pageprev.width() + pagenext.width()) / 4}
                pageprev.css($.extend({left: hw + len}, styles));
                pagenext.css($.extend({right: len}, styles));
            } else {
                pageprev.removeAttr('style');
                pagenext.removeAttr('style');
            }
        }).trigger('resize');
        </script>
    

</body>
</html>
